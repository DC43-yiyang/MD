{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import colors\n",
    "import seaborn as sb\n",
    "from gprofiler import GProfiler\n",
    "import seaborn as sns\n",
    "\n",
    "import rpy2.rinterface_lib.callbacks\n",
    "import logging\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "import anndata2ri\n",
    "\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, silhouette_score\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_clustering_metrics(adata, embedding, cluster_key):\n",
    "    silhouette_avg = silhouette_score(adata.obsm[embedding], adata.obs[cluster_key])\n",
    "    ch_score = calinski_harabasz_score(adata.obsm[embedding], adata.obs[cluster_key])\n",
    "    db_score = davies_bouldin_score(adata.obsm[embedding], adata.obs[cluster_key])\n",
    "    \n",
    "    return {\n",
    "        \"Silhouette Score\": silhouette_avg,\n",
    "        \"Calinski-Harabasz Score\": ch_score,\n",
    "        \"Davies-Bouldin Score\": db_score\n",
    "    }\n",
    "\n",
    "def preprocess(adata, norm_method):\n",
    "    adata_copy = adata.copy()\n",
    "    \n",
    "    # Normalization\n",
    "    if norm_method == 'total':\n",
    "        sc.pp.normalize_total(adata_copy, target_sum=1e4)\n",
    "    elif norm_method == 'size_factors':\n",
    "        sc.pp.normalize_total(adata_copy, target_sum=1e6)\n",
    "        sc.pp.log1p(adata_copy)\n",
    "        adata_copy.obs['size_factors'] = adata_copy.obs['n_counts'] / adata_copy.obs['n_counts'].median()\n",
    "        adata_copy.X /= adata_copy.obs['size_factors'].values[:, None]\n",
    "    # elif norm_method == 'pearson_residuals':\n",
    "    #     # Pearson residuals as an alternative to SCTransform\n",
    "    #     counts = adata_copy.X.toarray() if sp.sparse.issparse(adata_copy.X) else adata_copy.X\n",
    "    #     size_factors = counts.sum(axis=1)\n",
    "    #     size_factors /= np.mean(size_factors)\n",
    "        \n",
    "    #     expected = np.outer(size_factors, counts.mean(axis=0))\n",
    "    #     variance = expected + expected**2 / 10  # assuming dispersion of 0.1\n",
    "        \n",
    "    #     pearson_residuals = (counts - expected) / np.sqrt(variance)\n",
    "    #     adata_copy.layers['pearson_residuals'] = pearson_residuals\n",
    "    #     adata_copy.X = adata_copy.layers['pearson_residuals']    \n",
    "    sc.pp.log1p(adata_copy)\n",
    "    \n",
    "    # Highly variable genes\n",
    "    sc.pp.highly_variable_genes(adata_copy, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "    adata_copy = adata_copy[:, adata_copy.var.highly_variable]\n",
    "    \n",
    "    return adata_copy\n",
    "\n",
    "def batch_correct_and_reduce(adata, batch_key):\n",
    "    # ComBat batch correction\n",
    "    sc.pp.combat(adata, key=batch_key)\n",
    "    \n",
    "    # PCA\n",
    "    sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack')\n",
    "    \n",
    "    # Compute neighbors\n",
    "    sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "    \n",
    "    # Compute UMAP for visualization\n",
    "    sc.tl.umap(adata)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def cluster_and_evaluate(adata, cluster_method, resolution, batch_key):\n",
    "    adata_copy = adata.copy()\n",
    "    \n",
    "    # Clustering\n",
    "    cluster_key = f'{cluster_method}_r{resolution}'\n",
    "    if cluster_method == 'louvain':\n",
    "        sc.tl.louvain(adata_copy, resolution=resolution, key_added=cluster_key)\n",
    "    elif cluster_method == 'leiden':\n",
    "        sc.tl.leiden(adata_copy, resolution=resolution, key_added=cluster_key)\n",
    "    \n",
    "    # # Visualization\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    # sc.pl.umap(adata_copy, color=batch_key, ax=ax1, show=False, title='Batch')\n",
    "    # sc.pl.umap(adata_copy, color=cluster_key, ax=ax2, show=False, title=f\"{cluster_method}, res={resolution}\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_clustering_metrics(adata_copy, 'X_umap', cluster_key)\n",
    "    \n",
    "    return adata_copy, metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "adata = sc.read('/home/yiyang/github/MD/data/mouse_afterQC.h5ad')\n",
    "\n",
    "# Define parameters\n",
    "norm_methods = ['total', 'size_factors']\n",
    "# norm_methods = ['pearson_residuals']\n",
    "\n",
    "cluster_methods = ['louvain', 'leiden']\n",
    "# cluster_methods = ['louvain']\n",
    "\n",
    "resolutions = [0.5, 1.0]\n",
    "# resolutions = [0.5]\n",
    "\n",
    "batch_key = 'sample'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing normalization method: total\n",
      "Performing batch correction and dimension reduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiyang/anaconda3/envs/scRNA-seq/lib/python3.11/site-packages/scanpy/preprocessing/_pca.py:385: FutureWarning: Argument `use_highly_variable` is deprecated, consider using the mask argument. Use_highly_variable=True can be called through mask_var=\"highly_variable\". Use_highly_variable=False can be called through mask_var=None\n",
      "  warn(msg, FutureWarning)\n",
      "/home/yiyang/anaconda3/envs/scRNA-seq/lib/python3.11/site-packages/scanpy/preprocessing/_pca.py:325: ImplicitModificationWarning: Setting element `.obsm['X_pca']` of view, initializing view as actual.\n",
      "  adata.obsm[\"X_pca\"] = X_pca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing total_louvain_r0.5...\n",
      "Results for total_louvain_r0.5:\n",
      "  Silhouette Score: 0.3483146131038666\n",
      "  Calinski-Harabasz Score: 11582.12212423765\n",
      "  Davies-Bouldin Score: 0.8483002548873645\n",
      "Processing total_louvain_r1.0...\n",
      "Results for total_louvain_r1.0:\n",
      "  Silhouette Score: 0.2834363579750061\n",
      "  Calinski-Harabasz Score: 11307.433438098104\n",
      "  Davies-Bouldin Score: 0.9048171244498766\n",
      "Processing total_leiden_r0.5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1065932/459586877.py:66: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n",
      "\n",
      " To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n",
      "  sc.tl.leiden(adata_copy, resolution=resolution, key_added=cluster_key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for total_leiden_r0.5:\n",
      "  Silhouette Score: 0.4218815863132477\n",
      "  Calinski-Harabasz Score: 12951.648958608\n",
      "  Davies-Bouldin Score: 0.6465722005332804\n",
      "Processing total_leiden_r1.0...\n",
      "Results for total_leiden_r1.0:\n",
      "  Silhouette Score: 0.277815580368042\n",
      "  Calinski-Harabasz Score: 11476.207362842864\n",
      "  Davies-Bouldin Score: 1.3744214746514452\n",
      "\n",
      "Processing normalization method: size_factors\n",
      "WARNING: adata.X seems to be already log-transformed.\n",
      "Performing batch correction and dimension reduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiyang/anaconda3/envs/scRNA-seq/lib/python3.11/site-packages/scanpy/preprocessing/_pca.py:385: FutureWarning: Argument `use_highly_variable` is deprecated, consider using the mask argument. Use_highly_variable=True can be called through mask_var=\"highly_variable\". Use_highly_variable=False can be called through mask_var=None\n",
      "  warn(msg, FutureWarning)\n",
      "/home/yiyang/anaconda3/envs/scRNA-seq/lib/python3.11/site-packages/scanpy/preprocessing/_pca.py:325: ImplicitModificationWarning: Setting element `.obsm['X_pca']` of view, initializing view as actual.\n",
      "  adata.obsm[\"X_pca\"] = X_pca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing size_factors_louvain_r0.5...\n",
      "Results for size_factors_louvain_r0.5:\n",
      "  Silhouette Score: 0.25558939576148987\n",
      "  Calinski-Harabasz Score: 6293.661010372554\n",
      "  Davies-Bouldin Score: 1.3193965663859304\n",
      "Processing size_factors_louvain_r1.0...\n",
      "Results for size_factors_louvain_r1.0:\n",
      "  Silhouette Score: 0.23467595875263214\n",
      "  Calinski-Harabasz Score: 6980.4843153206175\n",
      "  Davies-Bouldin Score: 1.7944441667470896\n",
      "Processing size_factors_leiden_r0.5...\n",
      "Results for size_factors_leiden_r0.5:\n",
      "  Silhouette Score: 0.2157232165336609\n",
      "  Calinski-Harabasz Score: 7105.269476970059\n",
      "  Davies-Bouldin Score: 1.0119014692851303\n",
      "Processing size_factors_leiden_r1.0...\n",
      "Results for size_factors_leiden_r1.0:\n",
      "  Silhouette Score: 0.26930302381515503\n",
      "  Calinski-Harabasz Score: 7519.138053925071\n",
      "  Davies-Bouldin Score: 0.9985774990847915\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for norm in norm_methods:\n",
    "    print(f\"\\nProcessing normalization method: {norm}\")\n",
    "    adata_preprocessed = preprocess(adata, norm)\n",
    "    \n",
    "    print(f\"Performing batch correction and dimension reduction...\")\n",
    "    adata_corrected = batch_correct_and_reduce(adata_preprocessed, batch_key)\n",
    "    \n",
    "    for cluster in cluster_methods:\n",
    "        for res in resolutions:\n",
    "            key = f\"{norm}_{cluster}_r{res}\"\n",
    "            print(f\"Processing {key}...\")\n",
    "            adata_clustered, metrics = cluster_and_evaluate(adata_corrected, cluster, res, batch_key)\n",
    "            results[key] = metrics\n",
    "            print(f\"Results for {key}:\")\n",
    "            for metric, value in metrics.items():\n",
    "                print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_louvain_r0.5': {'Silhouette Score': 0.3483146,\n",
       "  'Calinski-Harabasz Score': 11582.12212423765,\n",
       "  'Davies-Bouldin Score': 0.8483002548873645},\n",
       " 'total_louvain_r1.0': {'Silhouette Score': 0.28343636,\n",
       "  'Calinski-Harabasz Score': 11307.433438098104,\n",
       "  'Davies-Bouldin Score': 0.9048171244498766},\n",
       " 'total_leiden_r0.5': {'Silhouette Score': 0.4218816,\n",
       "  'Calinski-Harabasz Score': 12951.648958608,\n",
       "  'Davies-Bouldin Score': 0.6465722005332804},\n",
       " 'total_leiden_r1.0': {'Silhouette Score': 0.27781558,\n",
       "  'Calinski-Harabasz Score': 11476.207362842864,\n",
       "  'Davies-Bouldin Score': 1.3744214746514452},\n",
       " 'size_factors_louvain_r0.5': {'Silhouette Score': 0.2555894,\n",
       "  'Calinski-Harabasz Score': 6293.661010372554,\n",
       "  'Davies-Bouldin Score': 1.3193965663859304},\n",
       " 'size_factors_louvain_r1.0': {'Silhouette Score': 0.23467596,\n",
       "  'Calinski-Harabasz Score': 6980.4843153206175,\n",
       "  'Davies-Bouldin Score': 1.7944441667470896},\n",
       " 'size_factors_leiden_r0.5': {'Silhouette Score': 0.21572322,\n",
       "  'Calinski-Harabasz Score': 7105.269476970059,\n",
       "  'Davies-Bouldin Score': 1.0119014692851303},\n",
       " 'size_factors_leiden_r1.0': {'Silhouette Score': 0.26930302,\n",
       "  'Calinski-Harabasz Score': 7519.138053925071,\n",
       "  'Davies-Bouldin Score': 0.9985774990847915}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRNA-seq",
   "language": "python",
   "name": "scrna-seq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
